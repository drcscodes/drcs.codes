## Information Theory

Information theory, a.k.a. communication theory[^Shannon1948], seeks to quantify surprise.

- Likely events have low information.
- Unlikey events have high information.
- Independent events have additive information.  E.g., tossing a coin twice had twice as much information as tossing a coin once.

[^Shannon1948]: https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf

## Self-Information

The self-information of an event $x$ is:

$$
I(x) = -log p(x)
$$

