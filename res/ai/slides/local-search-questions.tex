\documentclass[addpoints]{exam}

\usepackage{verbatim, multicol, tabularx,hyperref, tikz, enumitem}
\usepackage{amsmath,amsthm, amssymb, stmaryrd, latexsym, bm, listings, qtree}
\usepackage[margin=1in]{geometry}

\lstset{
  extendedchars=\true,
  inputencoding=utf8,
  literate=
  {é}{{\'{e}}}1
  {è}{{\`{e}}}1
  {ê}{{\^{e}}}1
  {ë}{{\¨{e}}}1
  {û}{{\^{u}}}1
  {ù}{{\`{u}}}1
  {â}{{\^{a}}}1
  {à}{{\`{a}}}1
  {î}{{\^{i}}}1
  {ô}{{\^{o}}}1
  {ç}{{\c{c}}}1
  {Ç}{{\c{C}}}1
  {É}{{\'{E}}}1
  {Ê}{{\^{E}}}1
  {À}{{\`{A}}}1
  {Â}{{\^{A}}}1
  {Î}{{\^{I}}}1
  {Ö}{{\"O}}1
  {Ä}{{\"A}}1
  {Ü}{{\"U}}1
  {ö}{{\"o}}1
  {ä}{{\"a}}1
  {ü}{{\"u}}1
  {ß}{{\ss}}1
  ,
  aboveskip=1mm,
  belowskip=1mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\scriptsize\ttfamily},
  numbers=left,
  frame=single,
  framextopmargin=0pt,
  framexbottommargin=0pt,
  breaklines=true,
  breakatwhitespace=true,
  keywordstyle=\color{blue},
  identifierstyle=\color{violet},
  stringstyle=\color{teal},
  commentstyle=\color{darkgray}
}

\hypersetup{colorlinks=true,urlcolor=blue}

\headheight = 0.05 in
\headsep = 0.05 in
\parskip = 0.05in
\parindent = 0.0in
\floatsep = 0.05in

\DeclareMathOperator*{\argmin}{arg\!min}
\DeclareMathOperator*{\argmax}{arg\!max}

\title{Local Search Review}
\author{Artificial Intelligence}
\date{}

\begin{document}
\maketitle

\begin{questions}

\setcounter{section}{0} % So that next \section is 1


\begin{center}
\includegraphics[height=1.5in]{../../deep-learning/slides/TrainConvexProb.pdf}
\end{center}

\question Which of the functions above is/are convex?

\begin{solution}[.25in]
Convex: b
\end{solution}


\question Which of the points above is/are a local minimum?

\begin{solution}[.25in]
Local minima:  1, 3, 7
\end{solution}


\question Which of the points above is/are a global minimum?

\begin{solution}[.25in]
Global minima: 2, 5, 6
\end{solution}

\question Write the basic hill-climbing algorithm.

\begin{solution}[3in]

\end{solution}

\question What is the main weakness of hill-climbing algorithms?

\begin{solution}[.75in]

\end{solution}

\question How can the basic hill-climbing algorithm be modified to overcome its weaknesses?

\begin{solution}[1.25in]

\end{solution}

\question How does simulated annealing avoid getting stuck in local minima?

\begin{solution}[1.25in]

\end{solution}

\question What is (stochastic) beam search?

\begin{solution}[1in]

\end{solution}


\question What does the mixing number parameter, $\rho$, in the basic algorithm control?

\begin{solution}[.5in]
The number of ``parents'' used to generate new candidate solutions.
\end{solution}

\question What do you have when you set $\rho = 1$ in the basic genetic algorithm?

\begin{solution}[.5in]
When $\rho = 1$, the basic genetic algorithm is equivalent to stochastic beam search.
\end{solution}

\question In gradient descent algorithms, what happens if you set the step size/learning rate parameter too high?

\begin{solution}[.5in]

\end{solution}

\question Define belief state.

\begin{solution}[.5in]

\end{solution}

\question What form does the solution (sequence of actions that leads to a goal state) to an environment with nondeterministic actions take?

\begin{solution}[.5in]
A conditional/contingency plan.
\end{solution}

\newpage

\question Is it possible to find a solution to a problem in a sensorless environment?

\begin{solution}[.75in]

\end{solution}

\question Describe the three-step state estimation procedure used by agents in partially observable environments.

\begin{solution}[3in]

\end{solution}


\end{questions}

\end{document}
