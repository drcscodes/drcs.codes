<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Dr. CS codes</title><meta name=viewport content="width=device-width"><link rel=stylesheet href=https://DrCS.codes/css/syntax.css><link rel=stylesheet href=https://DrCS.codes/css/main.css><link rel=stylesheet href=https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css integrity=sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO crossorigin=anonymous><link href=https://DrCS.codes/css/navbar-top-fixed.css rel=stylesheet></head><body><nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"><a class=navbar-brand href=/machine-learning></a>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbarCollapse aria-controls=navbarCollapse aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="navbar-collapse collapse" id=navbarCollapse><ul class="navbar-nav mr-auto"></ul><ul class="navbar-nav pull-right"><li class="nav-item pull-right"><a class=nav-link href=https://DrCS.codes>Dr. CS codes</a></li></ul></div></nav><main role=main class=container><p>% Linear Separators
% The Perceptron Learning Algorithm</p><h2 id=learning-problem-setup>Learning Problem Setup</h2><p>Every machine learning problem contains the following elements:</p><ul><li>An input $\vec{x}$<ul><li>(though, as we&rsquo;ll see later, $\vec{x}$ can be a list aof arbitrary feature values, not necessarily a vector)</li></ul></li><li>An unkown target function $f: \mathcal{X} \rightarrow \mathcal{Y}$</li><li>A data set $\mathcal{D}$</li><li>A learning model, which consists of<ul><li>a hypothesis class $\mathcal{H}$, and</li><li>a learning algorithm.</li></ul></li></ul><p>A learning algorithm uses elements of $\mathcal{D}$ to estimate parameters of of a particular $h(\vec{x})$ from $\mathcal{H}$ which maps every $\vec{x}$ to an element of $\mathcal{Y}$.</p><h2 id=example-credit-scoring>Example: Credit Scoring</h2><p>Let&rsquo;s create a credit score based on two variables: age and income (in thousands), which are real numbers.</p><ul><li><p>An input $\vec{x}$ is a vector in $\mathbb{R}^2$. For example, a 25 year-old person making $60,000 would be represented by the vector $(24, 60)$.</p></li><li><p>&ldquo;Credit score&rdquo; = $\sum_{i=1}^{d} w_i x_i$</p></li></ul><p>In other words:</p><ul><li>Approve credit if $\sum_{i=1}^{d} w_i x_i$ > threshold</li><li>Deny credit if $\sum_{i=1}^{d} w_i x_i$ &lt; threshold</li></ul><p>The weights $w_i$ represent the importance of corresponding features of input instances.</p><h2 id=learning-model>Learning Model</h2><p>Our credit score:</p><ul><li>Approve credit if $\sum_{i=1}^{d} w_i x_i$ > threshold</li><li>Deny credit if $\sum_{i=1}^{d} w_i x_i$ &lt; threshold</li></ul><p>Can be turned into a learning model as</p><p>$$
h(x) = sign((\sum_{i=1}^{d} w_i x_i) + w_0)
$$</p><p>The &ldquo;bias weight&rdquo; $w_0$ corresponds to the threshold.</p><p>Our learning model is a discriminant &ndash; for an instance $\vec{x}$ it returns $+1$ or $-1$.</p><h2 id=the-credit-data-set>The Credit Data Set</h2><p>Let&rsquo;s look at a particular data set, $\mathcal{D}$, stored in <a href=../code/credit.csv>credit.csv</a></p><ul><li>Each data point represents a previous customer</li><li>Since this is is supervised learning, every data point has an associated label: $+1$ for a customer off whom the bank made money, $-1$ for a customer off whom the bank lost money</li></ul><p>We can load the data set directly into a DataFrame:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Python data-lang=Python><span style=display:flex><span>In [<span style=color:#ae81ff>34</span>]: credit <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(credit<span style=color:#f92672>.</span>csv)                                                    
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>35</span>]: credit                                                                                   
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>35</span>]: 
</span></span><span style=display:flex><span>    age  income  approve
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>    <span style=color:#ae81ff>64</span>      <span style=color:#ae81ff>90</span>        <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>    <span style=color:#ae81ff>78</span>      <span style=color:#ae81ff>92</span>        <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>    <span style=color:#ae81ff>38</span>      <span style=color:#ae81ff>80</span>        <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>    <span style=color:#ae81ff>29</span>      <span style=color:#ae81ff>66</span>       <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>    <span style=color:#ae81ff>94</span>      <span style=color:#ae81ff>79</span>        <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>...</span> additional rows elided
</span></span></code></pre></div><h2 id=credit-data-plot>Credit Data Plot</h2><p>A scatter plot gives us intuition about the structure of the data.</p><p><img src=credit-scatter.png alt>{height=70%}</p><p>Is there a line that separates the +s from the -s?</p><h2 id=a-linear-separator>A Linear Separator</h2><p>Here&rsquo;s a line that separates the data into classes.</p><p><img src=credit-scatter-separator.png alt>{height=70%}</p><p>Are there other lines? How many of these lines are there?</p><h2 id=version-spaces>Version Spaces</h2><p>A <em>version space</em> is the set of all $h$ in $\mathcal{H}$ consistent with our training data. For our credit data, it&rsquo;s the set of all lines that separate the classes.</p><p><img src=credit-scatter.png alt>{height=70%}</p><p>Now the question is, how can we find one of these lines mechanically?</p><h2 id=the-perceptron-hypothesis-class>The Perceptron Hypothesis Class</h2><p>The set of lines (more generally, hyperplanes) is a hypothesis class known as the <em>perceptron</em>.</p><p>$$
\mathcal{H} = {h(\vec{x}) = sign(\vec{w}^T \cdot \vec{x})}
$$</p><p>where</p><p>::::{.columns valign=&ldquo;center&rdquo;}
::: {.column width=&ldquo;40%&rdquo;}</p><p>$$
\vec{w} =
\begin{bmatrix}
w_{0} \
w_{1} \
\vdots \
w_{d}
\end{bmatrix}
\in \mathbb{R}^d
$$</p><p>:::
::: {.column width=&ldquo;40%&rdquo;}</p><p>$$
\vec{x} =
\begin{bmatrix}
1 \
x_{1} \
\vdots \
x_{d}
\end{bmatrix}
\in {1} \times \mathbb{R}^d
$$</p><p>:::
::::</p><p>Notice that we enode the bias term as $w_0$ and we prepend all data points with $1$ so that a simple dot product of the weight vector with a data point gives us the weighted sum we formalized earlier.</p><h2 id=the-perceptron-learning-algorithm>The Perceptron Learning Algorithm</h2><p>A simple algorithm to find a linear separator is the perceptron learning algorithm:</p><p>Given a data set $\mathcal{D}$ with each $\vec{x_i}$ in $\mathcal{D}$ prepended with a $1$, and labels $\vec{y}$</p><ol><li><p>Initialize $\vec{w} = (w_0, w_1, &mldr;, w_d)$ with zeros or random values.</p></li><li><p>As long as there is a $\vec{x_i}$ in $\mathcal{D}$ for which $sign(\vec{w}^T \cdot \vec{x}) \ne y_i$</p><ul><li>Update $\vec{w}$ using the update rule:<ul><li>$\vec{w}(t + 1) = \vec{w}(t) + y_i \vec{x_i}$ ($t$ is &ldquo;time&rdquo;, or iteration number)</li></ul></li></ul></li></ol><p>When the algorithm finishes, $\vec{w}$ is a line separating the two classes (assuming $\mathcal{D}$ is linearly separable).</p><p>Let&rsquo;s see this algorithm in action&mldr;</p><h2 id=the-general-form-of-learning-algorithms>The General Form of Learning Algorithms</h2><p>The Perceptron Learning Algorithm exemplifies the general form of learning algorithms</p><ol><li><p>Initialize a model&rsquo;s parameters to some initial values.</p></li><li><p>Until some stopping criterion is reached (e.g., error within bounds)</p><ul><li>Evaluate the model on some subset of the data $\mathcal{D}$</li><li>If error is present, update the model&rsquo;s parameters to reduce the error<ul><li>The magnitude of the correction is often captured in a &ldquo;learning rate&rdquo; hyperparameter, often represented by $\eta$ or $\alpha$</li></ul></li></ul></li></ol><p>When the algorithm is finished, you have a model, a particular $h \in \mathcal{H}$, that &ldquo;fits&rdquo; the training data.</p><h2 id=closing-thoughts>Closing Thoughts</h2><p>The perceptron model and the perceptron learning algorithm give us a simple, easy to grasp introduction to general issues in machine learning.</p><p>In the coming weeks we will develop a more sophisticated conceptual and algorithmic toolkit.</p><ul><li><p>For our PLA we chose a data set with a strong (and rare) property: perfect linear separability. What if we have data that are not linearly separable?</p></li><li><p>How do we model error?</p></li><li><p>How do we deal with noise?</p></li><li><p>What if our data can&rsquo;t be represented as vectors?</p></li></ul></main><script src=https://code.jquery.com/jquery-3.2.1.slim.min.js integrity=sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js integrity=sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q crossorigin=anonymous></script>
<script src=../js/bootstrap.min.js></script></body></html>