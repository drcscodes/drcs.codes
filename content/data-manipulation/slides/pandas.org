#+TITLE: Pandas
#+AUTHOR: Data Manipulation in Python
#+EMAIL:
#+DATE:
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS: H:2 toc:nil num:t ^:{}
#+BEAMER_FRAME_LEVEL: 2
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [smaller]
#+LaTeX_HEADER: \usepackage{verbatim, multicol, tabularx,}
#+LaTeX_HEADER: \usepackage{amsmath,amsthm, amssymb, latexsym, listings, qtree}
#+LaTeX_HEADER: \lstset{frame=tb, aboveskip=1mm, belowskip=0mm, showstringspaces=false, columns=flexible, basicstyle={\scriptsize\ttfamily}, numbers=left, frame=single, breaklines=true, breakatwhitespace=true}
#+LaTeX_HEADER: \setbeamertemplate{footline}[frame number]
#+LaTeX_HEADER: \hypersetup{colorlinks=true,urlcolor=blue}
#+LaTeX_HEADER: \logo{\includegraphics[height=.75cm]{GeorgiaTechLogo-black-gold.png}}

* Pandas

** Pandas

- Built on NumPy
- Adds data structures and data manipulation tools
- Enables easier data cleaning and analysis

#+BEGIN_SRC python
import pandas as pd
pd.set_option("display.width", 120)
#+END_SRC

That last line allows you to display DataFrames with many columns without wrapping.

** Pandas Fundamentals

Three fundamental Pandas data structures:

- ~Series~ - a one-dimensional array of values indexed by a ~pd.Index~
- ~Index~ - an array-like object used to access elements of a ~Series~ or ~DataFrame~
- ~DataFrame~ - a two-dimensional array with flexible row indices and column names

** Series from List

#+BEGIN_SRC python
In [4]: data = pd.Series(['a','b','c','d'])

In [5]: data
Out[5]:
0    a
1    b
2    c
3    d
dtype: object
#+END_SRC

The 0..3 in the left column are the ~pd.Index~ for ~data~:

#+BEGIN_SRC python
In [7]: data.index
Out[7]: RangeIndex(start=0, stop=4, step=1)
#+END_SRC

The elements from the Python list we passed to the ~pd.Series~ constructor make up the values:

#+BEGIN_SRC python
In [8]: data.values
Out[8]: array(['a', 'b', 'c', 'd'], dtype=object)
#+END_SRC
Notice that the values are stored in a Numpy array.

** Series from Sequence

You can construct a list from any definite sequence:

#+BEGIN_SRC python
In [24]: pd.Series(np.loadtxt('exam1grades.txt'))
Out[24]:
0       72.0
1       72.0
2       50.0
...
134     87.0
dtype: float64
#+END_SRC

or

#+BEGIN_SRC python
In [25]: pd.Series(open('exam1grades.txt').readlines())
Out[25]:
0       72\n
1       72\n
2       50\n
...
134     87\n
dtype: object
#+END_SRC

... but not an indefinite sequence:

#+BEGIN_SRC python
In [26]: pd.Series(open('exam1grades.txt'))
...
TypeError: object of type '_io.TextIOWrapper' has no len()
#+END_SRC

** Series from Dictionary

#+BEGIN_SRC python
salary = {"Data Scientist": 110000,
          "DevOps Engineer": 110000,
          "Data Engineer": 106000,
          "Analytics Manager": 112000,
          "Database Administrator": 93000,
          "Software Architect": 125000,
          "Software Engineer": 101000,
          "Supply Chain Manager": 100000}
#+END_SRC
Create a ~pd.Series~ from a ~dict~: [fn:1]

#+BEGIN_SRC python
In [14]: salary_data = pd.Series(salary)

In [15]: salary_data
Out[15]:
Analytics Manager         112000
Data Engineer             106000
Data Scientist            110000
Database Administrator     93000
DevOps Engineer           110000
Software Architect        125000
Software Engineer         101000
Supply Chain Manager      100000
dtype: int64
#+END_SRC

The index is a sorted sequence of the keys of the dictionary passed to ~pd.Series~

[fn:1] [[https://www.glassdoor.com/List/Best-Jobs-in-America-LST_KQ0,20.htm][https://www.glassdoor.com/List/Best-Jobs-in-America-LST_KQ0,20.htm]]

** Series with Custom Index

General form of Series constructor is ~pd.Series(data, index=index)~

- Default is integer sequence for sequence data and sorted keys of dictionaries
- Can provide a custom index:

#+BEGIN_SRC python
In [29]: pd.Series([1,2,3], index=['a', 'b', 'c'])
Out[29]:
a    1
b    2
c    3
dtype: int64
#+END_SRC

The index object itself is an immutable array with set operations.

#+BEGIN_SRC python
In [30]: i1 = pd.Index([1,2,3,4])

In [31]: i2 = pd.Index([3,4,5,6])

In [32]: i1[1:3]
Out[32]: Int64Index([2, 3], dtype='int64')

In [33]: i1 & i2 # intersection
Out[33]: Int64Index([3, 4], dtype='int64')

In [34]: i1 | i2 # union
Out[34]: Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')

In [35]: i1 ^ i2 # symmetric difference
Out[35]: Int64Index([1, 2, 5, 6], dtype='int64')
#+END_SRC

** Series Indexing and Slicing

Indexing feels like dictionary access due to flexible index objects:

#+BEGIN_SRC python
In [37]: data = pd.Series(['a', 'b', 'c', 'd'])

In [38]: data[0]
Out[38]: 'a'

In [39]: salary_data['Software Engineer']
Out[39]: 101000
#+END_SRC

But you can also slice using these flexible indices:
#+BEGIN_SRC python
In [40]: salary_data['Data Scientist':'Software Engineer']
Out[40]:
Data Scientist            110000
Database Administrator     93000
DevOps Engineer           110000
Software Architect        125000
Software Engineer         101000
dtype: int64
#+END_SRC

** Basic DataFrame Structure

A DataFrame is a series Serieses with the same keys. For example, consider the following dictionary of dictionaries meant to leverage your experience with spreadsheets (in [[http://datamastery.github.io/code/analytics/spreadsheet.py][spreadsheet.py]]):

#+BEGIN_SRC python
In [5]: import spreadsheet; spreadsheet.cells

Out[5]:
{'A': {1: 'A1', 2: 'A2', 3: 'A3'},
 'B': {1: 'B1', 2: 'B2', 3: 'B3'},
 'C': {1: 'C1', 2: 'C2', 3: 'C3'},
 'D': {1: 'D1', 2: 'D2', 3: 'D3'}}
#+END_SRC

All of these dictionaries have the same keys, so we can pass this dictionary of dictionaries to the DataFrame constructor:

#+BEGIN_SRC python
In [7]: ss = pd.DataFrame(spreadsheet.cells); ss

Out[7]:
    A   B   C   D
1  A1  B1  C1  D1
2  A2  B2  C2  D2
3  A3  B3  C3  D3
#+END_SRC

- Each column is a Series whose keys (index) are the values printed to the left (1, 2 and 3).

- Each row is a Series whose keys (index) are the column headers.

Try evaluating ~ss.columns~ and ~ss.index~.

** DataFrame Example

Download [[http://datamastery.github.io/code/analytics/hotjobs.py][hotjobs.py]] and do a ~%load hotjobs.py~ (to evaluate the code in the top-level namespace instead of importing it).

#+BEGIN_SRC python
In [42]: jobs = pd.DataFrame({'salary': salary, 'openings': openings})

In [43]: jobs
Out[43]:
                        openings  salary
Analytics Manager           1958  112000
Data Engineer               2599  106000
Data Scientist              4184  110000
Database Administrator      2877   93000
DevOps Engineer             2725  110000
Software Architect          2232  125000
Software Engineer          17085  101000
Supply Chain Manager        1270  100000
UX Designer                 1691   92500
#+END_SRC

#+BEGIN_SRC python
In [46]: jobs.index
Out[46]:
Index(['Analytics Manager', 'Data Engineer', 'Data Scientist',
       'Database Administrator', 'DevOps Engineer', 'Software Architect',
       'Software Engineer', 'Supply Chain Manager', 'UX Designer'],
      dtype='object')

In [47]: jobs.columns
Out[47]: Index(['openings', 'salary'], dtype='object')
#+END_SRC

** Simple DataFrame Indexing

Simplest indexing of DataFrame is by column name.

#+BEGIN_SRC python
In [48]: jobs['salary']
Out[48]:
Analytics Manager         112000
Data Engineer             106000
Data Scientist            110000
Database Administrator     93000
DevOps Engineer           110000
Software Architect        125000
Software Engineer         101000
Supply Chain Manager      100000
UX Designer                92500
Name: salary, dtype: int64
#+END_SRC


Each colum is a Series:
#+BEGIN_SRC python
In [49]: type(jobs['salary'])
Out[49]: pandas.core.series.Series
#+END_SRC


** General Row Indexing

The ~loc~ indexer indexes by row name:
#+BEGIN_SRC python
In [13]: jobs.loc['Software Engineer']
Out[13]:
openings     17085
salary      101000
Name: Software Engineer, dtype: int64

In [14]: jobs.loc['Data Engineer':'Databse Administrator']
Out[14]:
                        openings  salary
Data Engineer               2599  106000
Data Scientist              4184  110000
Database Administrator      2877   93000
#+END_SRC

Note that slice ending is inclusive when indexing by name.

The ~iloc~ indexer indexes rows by position:
#+BEGIN_SRC python
In [15]: jobs.iloc[1:3]
Out[15]:
                openings  salary
Data Engineer       2599  106000
Data Scientist      4184  110000
#+END_SRC

Note that slice ending is exclusive when indexing by integer position.


** Special Case Row Indexing

#+BEGIN_SRC python
In [16]: jobs[:2]
Out[16]:
                   openings  salary
Analytics Manager      1958  112000
Data Engineer          2599  106000

In [17]: jobs[jobs['salary'] > 100000]
Out[17]:
                    openings  salary
Analytics Manager       1958  112000
Data Engineer           2599  106000
Data Scientist          4184  110000
DevOps Engineer         2725  110000
Software Architect      2232  125000
Software Engineer      17085  101000
#+END_SRC

These are shortcuts for ~loc~ and ~iloc~ indexing:

#+BEGIN_SRC python
In [20]: jobs.iloc[:2]
Out[20]:
                   openings  salary
Analytics Manager      1958  112000
Data Engineer          2599  106000

In [21]: jobs.loc[jobs['salary'] > 100000]
Out[21]:
                    openings  salary
Analytics Manager       1958  112000
Data Engineer           2599  106000
Data Scientist          4184  110000
DevOps Engineer         2725  110000
Software Architect      2232  125000
Software Engineer      17085  101000
#+END_SRC

** Aggregate Functions

The values in a series is a ~numpy.ndarray~, so you can use NumPy functions, broadcasting, etc.

- Average salary for all these jobs:

#+BEGIN_SRC python
In [14]: np.average(jobs['salary'])
Out[14]: 107125.0
#+END_SRC

- Total number of openings:

#+BEGIN_SRC python
In [15]: np.sum(jobs['openings'])
Out[15]: 34930
#+END_SRC

And so on.

** Adding Columns

Add column by broadcasting a constant value:
#+BEGIN_SRC python
In [16]: jobs['DM Prepares'] = True

In [17]: jobs
Out[17]:
                        openings  salary  DM Prepares
Analytics Manager           1958  112000         True
Data Engineer               2599  106000         True
Data Scientist              4184  110000         True
Database Administrator      2877   93000         True
DevOps Engineer             2725  110000         True
Software Architect          2232  125000         True
Software Engineer          17085  101000         True
Supply Chain Manager        1270  100000         True
#+END_SRC

Add column by computing value based on row's data:

#+BEGIN_SRC python
In [25]: jobs['Percent Openings'] = jobs['openings'] / np.sum(jobs['openings'])

In [26]: jobs
Out[26]:
                        openings  salary  DM Prepares  Percent Openings
Analytics Manager           1958  112000         True          0.056055
Data Engineer               2599  106000         True          0.074406
Data Scientist              4184  110000         True          0.119782
Database Administrator      2877   93000         True          0.082365
DevOps Engineer             2725  110000         True          0.078013
Software Architect          2232  125000         True          0.063899
Software Engineer          17085  101000         True          0.489121
Supply Chain Manager        1270  100000         True          0.036358
#+END_SRC

** CSV Files

Pandas has a very powerful CSV reader. Do this in iPython (or ~help(pd.read_csv)~ in Python):

#+BEGIN_SRC python
pd.read_csv?
#+END_SRC

Now let's read the [[http://datamastery.github.io/exercises/super-grades.csv][~super-grades.csv~]] file and re-do [[http://datamastery.github.io/exercises/calc-grades.html][Calc Grades]] exercise using Pandas.


** Read a CSV File into a DataFrame

~super-grades.csv~ contains:
#+BEGIN_SRC python
Student,Exam 1,Exam 2,Exam 3
Thorny,100,90,80
Mac,88,99,111
Farva,45,56,67
Rabbit,59,61,67
Ursula,73,79,83
Foster,89,97,101
#+END_SRC

The first line is a header, which Pandas will infer, and we want to use the first column for index values:

#+BEGIN_SRC python
sgs = pd.read_csv('super-grades.csv', index_col=0)
#+END_SRC

Now we have the DataFrame we want:

#+BEGIN_SRC python
In [3]: sgs = pd.read_csv('super-grades.csv', index_col=0)

In [4]: sgs
Out[4]:
         Exam 1  Exam 2  Exam 3
Student
Thorny      100      90      80
Mac          88      99     111
Farva        45      56      67
Rabbit       59      61      67
Ursula       73      79      83
Foster       89      97     101
#+END_SRC

** Adding a Calculated Column to a DataFrame

We've seen how to add a column broadcast from a scalar value or a simple calculation from another column. Now let's add a column with the average grades for each student.

If we apply this to the DataFrame we get a Series with averages. Notice that we're "collapsing" columns (axis=1), that is, calculating values from a row like we did in NumPy:

#+BEGIN_SRC python
In [33]: sgs.apply(course_avg, axis=1)
Out[33]:
Student
Thorny    90.000000
Mac       99.333333
Farva     56.000000
Rabbit    62.333333
Ursula    78.333333
Foster    95.666667
dtype: float64
#+END_SRC

So we just add this series to the DataFrame:

#+BEGIN_SRC python
In [35]: sgs["avg"] = sgs.apply(course_avg, axis=1); sgs
Out[35]:
         Exam 1  Exam 2  Exam 3        avg
Student
Thorny      100      90      80  90.000000
Mac          88      99     111  99.333333
Farva        45      56      67  56.000000
Rabbit       59      61      67  62.333333
Ursula       73      79      83  78.333333
Foster       89      97     101  95.666667
#+END_SRC

** Appending DataFrames

Now let's add a new row containing the averages for each exam.

- We can get the item averages by applying ~np.mean~ to the columns (axis=0 -- "collapsing" rows):

#+BEGIN_SRC python
In [35]: sgs.apply(np.mean, axis=0)
Out[35]:
Exam 1    75.666667
Exam 2    80.333333
Exam 3    84.833333
avg       80.277778
dtype: float64
#+END_SRC

- We can turn this Series into a DaraFrame with the label we want:

#+BEGIN_SRC python
In [38]: pd.DataFrame({"ItemAverage": sgs.apply(np.mean, axis=0)})
Out[38]:
        ItemAverage
Exam 1    75.666667
Exam 2    80.333333
Exam 3    84.833333
avg       80.277778
#+END_SRC

** DataFrame Transpose

- But we need to give this DataFrame the same shape as our grades DataFrame:

#+BEGIN_SRC python
In [41]: item_avgs = pd.DataFrame({"Item Avg": sgs.apply(np.mean, axis=0)}).transpose()

In [43]: item_avgs
Out[43]:
             Exam 1     Exam 2     Exam 3        avg
Item Avg  75.666667  80.333333  84.833333  80.277778
#+END_SRC

Then we can simply append the DataFrame because it has the same columns:

#+BEGIN_SRC python
In [24]: sgs = sgs.append(item_avgs)

In [25]: sgs
Out[25]:
              Exam 1     Exam 2      Exam 3        avg
Thorny    100.000000  90.000000   80.000000  90.000000
Mac        88.000000  99.000000  111.000000  99.333333
Farva      45.000000  56.000000   67.000000  56.000000
Rabbit     59.000000  61.000000   67.000000  62.333333
Ursula     73.000000  79.000000   83.000000  78.333333
Foster     89.000000  97.000000  101.000000  95.666667
Item Avg   75.666667  80.333333   84.833333  80.277778
#+END_SRC

Note that ~append~ is non-destructive, so we have to reassign its returned DataFrame to sgs.

** Adding a Letter Grades Column

Adding a column with letter grades is easier than adding a column with a more complex calculation.

#+BEGIN_SRC python
In [40]: sgs['Grade'] = \
    ...:     np.where(sgs['avg'] >= 90, 'A',
    ...:              np.where(sgs['avg'] >= 80, 'B',
    ...:                       np.where(sgs['avg'] >= 70, 'C',
    ...:                                np.where(sgs['avg'] >= 60, 'D',
    ...:                                         'D'))))
    ...:

In [41]: sgs
Out[41]:
              Exam 1     Exam 2      Exam 3        avg Grade
Thorny    100.000000  90.000000   80.000000  90.000000     A
Mac        88.000000  99.000000  111.000000  99.333333     A
Farva      45.000000  56.000000   67.000000  56.000000     D
Rabbit     59.000000  61.000000   67.000000  62.333333     D
Ursula     73.000000  79.000000   83.000000  78.333333     C
Foster     89.000000  97.000000  101.000000  95.666667     A
Item Avg   75.666667  80.333333   84.833333  80.277778     B
#+END_SRC

** Grouping and Aggregation

Grouping and aggregation can be conceptualized as a *split, apply, combine* pipeline.

- Split by Grade

#+BEGIN_SRC python
              Exam 1     Exam 2      Exam 3        avg Grade
Thorny    100.000000  90.000000   80.000000  90.000000     A
Mac        88.000000  99.000000  111.000000  99.333333     A
Foster     89.000000  97.000000  101.000000  95.666667     A
#+END_SRC

#+BEGIN_SRC python
              Exam 1     Exam 2      Exam 3        avg Grade
Item Avg   75.666667  80.333333   84.833333  80.277778     B
#+END_SRC

#+BEGIN_SRC python
              Exam 1     Exam 2      Exam 3        avg Grade
Ursula     73.000000  79.000000   83.000000  78.333333     C
#+END_SRC

#+BEGIN_SRC python
              Exam 1     Exam 2      Exam 3        avg Grade
Farva      45.000000  56.000000   67.000000  56.000000     D
Rabbit     59.000000  61.000000   67.000000  62.333333     D
#+END_SRC

- Apply some aggregation function to each group, such as sum, mean, count.

- Combine results of function applications to get final results for each group.

** Letter Grades Counts

Here's how to find the counts of letter grades for our super troopers:

#+BEGIN_SRC python
In [58]: sgs['Grade'].groupby(sgs['Grade']).count()
Out[58]:
Grade
A    3
B    1
C    1
D    2
Name: Grade, dtype: int64
#+END_SRC


# ** Data Selection in Series

# #+BEGIN_SRC python

# #+END_SRC


# ** Data Selection in DataFrame

# #+BEGIN_SRC python

# #+END_SRC


# ** Universal Functions

# #+BEGIN_SRC python

# #+END_SRC


# ** Index Alignment

# #+BEGIN_SRC python

# #+END_SRC


# ** UFuncs on DataFrames and Series

# #+BEGIN_SRC python

# #+END_SRC


# ** Missing Data

# #+BEGIN_SRC python

# #+END_SRC


# ** Hierarchical Indexing

# #+BEGIN_SRC python

# #+END_SRC


# ** Concatenating Datasets

# #+BEGIN_SRC python

# #+END_SRC


# ** Merging Datasets

# Relational algebra for Pandas DataFrames

# #+BEGIN_SRC python

# #+END_SRC


# ** Aggregation

# #+BEGIN_SRC python

# #+END_SRC


# ** Grouping

# #+BEGIN_SRC python

# #+END_SRC


# ** Pivot Tables

# #+BEGIN_SRC python

# #+END_SRC


# ** String Operations

# #+BEGIN_SRC python

# #+END_SRC


# ** Time Series

# #+BEGIN_SRC python

# #+END_SRC

** Messy CSV Files

Remember the [[../exercises/tides.html][Tides Exercise]]? Pandas's ~read_csv~ can handle most of the data pre-processing:

#+BEGIN_SRC python
pd.read_csv('wpb-tides-2017.txt', sep='\t', skiprows=14, header=None,
            usecols=[0,1,2,3,5,7],
            names=['Date', 'Day', 'Time', 'Pred(ft)', 'Pred(cm)', 'High/Low'],
            parse_dates=['Date','Time'])
#+END_SRC

Let's use the indexing and data selection techniques we've learned to re-do the  [[../exercises/tides.html][Tides Exercise]] as a Jupyter Notebook. For convenience, ~wpb-tides-2017.txt~ is in the [[https://github.com/cs2316/cs2316.github.io/tree/master/code/analytics][code/analytics]] directory, or you can [[../code/analytics/wpb-tides-2017.txt][download it]].

** Reading SQL Databases

Let's create a realistically sized grades example dataset using fake student names. We'll get the names from the [[https://dev.mysql.com/doc/sakila/en/][Sakila Sample Database]].

#+BEGIN_SRC python
  import numpy as np
  import pandas as pd
  import pymysql

  sakila = pymysql.connect(host="localhost",
                           user="root",
                           password="",
                           db="sakila",
                           charset="utf8mb4",
                           cursorclass=pymysql.cursors.DictCursor)

  names = pd.read_sql("select first_name, last_name from actor", con = sakila)
  names.head()
#+END_SRC

#+BEGIN_SRC python
    first_name     last_name
  0   PENELOPE       GUINESS
  1       NICK      WAHLBERG
  2         ED         CHASE
  3   JENNIFER         DAVIS
  4     JOHNNY  LOLLOBRIGIDA
#+END_SRC

** Creating Datasets

Look at the [[https://github.com/datamastery/datamastery.github.io/blob/master/code/analytics/sakila-grades.ipynb][sakil-grades.ipynb]] notebook for an example of extracting data from a database and creating a realistically sized fake data set similar to the grades file downladed from Canvas.

There's also an [[https://orgmode.org/][org-mode]] version for Emacs users: [[https://github.com/datamastery/datamastery.github.io/blob/master/code/analytics/sakila-grades.org][sakila-grades.org]]
